{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 16:07:44.824307: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 16:07:44.839161: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744367864.856328   52810 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744367864.861060   52810 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744367864.873760   52810 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744367864.873779   52810 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744367864.873781   52810 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744367864.873783   52810 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 16:07:44.878290: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/kunalbhande/.local/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "IMG_SIZE = 128 \n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 2\n",
    "NOISE_DIM = 256\n",
    "EPOCHS = 2000\n",
    "\n",
    "MAX_LEN = 20\n",
    "VOCAB_SIZE = 5000\n",
    "EMBED_DIM = 256\n",
    "\n",
    "n_critic = 2\n",
    "\n",
    "with open('./data/captions.txt') as f:\n",
    "    all_captions = [line.strip().split('|')[1] for line in f]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token='<unk>')\n",
    "tokenizer.fit_on_texts(all_captions)\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=VOCAB_SIZE,     \n",
    "    output_dim=EMBED_DIM,\n",
    "    input_length=MAX_LEN\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_caption(caption):\n",
    "    seq = tokenizer.texts_to_sequences([caption.numpy().decode('utf-8')])[0]\n",
    "    padded = pad_sequences([seq], maxlen=MAX_LEN)[0].astype(np.int32)\n",
    "    return padded\n",
    "\n",
    "def tf_encode_caption(caption):\n",
    "    encoded = tf.py_function(encode_caption, inp=[caption], Tout=tf.int32)\n",
    "    encoded.set_shape([MAX_LEN])\n",
    "    return encoded\n",
    "\n",
    "def load_image_caption_dataset(img_folder, caption_file):\n",
    "    image_paths = []\n",
    "    captions = []\n",
    "\n",
    "    with open(caption_file, 'r') as f:\n",
    "        for line in f:\n",
    "            img_name, caption = line.strip().split(\"|\")\n",
    "            image_paths.append(os.path.join(img_folder, img_name))\n",
    "            captions.append(caption)\n",
    "\n",
    "    def gen():\n",
    "        for img_path, caption in zip(image_paths, captions):\n",
    "            img = tf.io.read_file(img_path)\n",
    "            img = tf.image.decode_jpeg(img, channels=3)\n",
    "            img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "            img = (tf.cast(img, tf.float32) / 127.5) - 1.0\n",
    "            yield img, caption\n",
    "    \n",
    "    text_lstm = tf.keras.layers.LSTM(EMBED_DIM)\n",
    "\n",
    "    def process(img, caption):\n",
    "        encoded = tf_encode_caption(caption)           \n",
    "        embedded = embedding_layer(encoded)   \n",
    "        \n",
    "        embedded = tf.expand_dims(embedded, 0)\n",
    "        text_vector = text_lstm(embedded)\n",
    "        text_vector = tf.squeeze(text_vector, 0)   \n",
    "              \n",
    "        return img, text_vector\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    dataset = dataset.map(process)\n",
    "    return dataset.shuffle(1000).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditioningAugmentation(layers.Layer):\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_mean = layers.Dense(embed_dim)\n",
    "        self.dense_log_sigma = layers.Dense(embed_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mean = self.dense_mean(inputs)\n",
    "        log_sigma = self.dense_log_sigma(inputs)\n",
    "        stddev = tf.exp(log_sigma)\n",
    "        epsilon = tf.random.normal(shape=tf.shape(mean))\n",
    "        return mean + stddev * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator():\n",
    "    noise_input = tf.keras.Input(shape=(NOISE_DIM,))\n",
    "    text_input = tf.keras.Input(shape=(EMBED_DIM,))\n",
    "\n",
    "    ca = ConditioningAugmentation(EMBED_DIM)(text_input)\n",
    "    x = layers.Concatenate()([noise_input, ca])\n",
    "\n",
    "    x = layers.Dense(4 * 4 * 512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Reshape((4, 4, 512))(x)\n",
    "\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    x = layers.Conv2D(256, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    x = layers.Conv2D(128, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    x = layers.Conv2D(32, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    x = layers.Conv2D(16, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(CHANNELS, kernel_size=3, padding='same', use_bias=False, activation='tanh')(x)\n",
    "\n",
    "    return tf.keras.Model([noise_input, text_input], x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator():\n",
    "    image_input = tf.keras.Input(shape=(128, 128, 3))  \n",
    "    text_input = tf.keras.Input(shape=(EMBED_DIM,)) \n",
    "\n",
    "    x = layers.Conv2D(64, 4, strides=2, padding='same')(image_input)  \n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "\n",
    "    x = layers.Conv2D(128, 4, strides=2, padding='same')(x) \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "\n",
    "    x = layers.Conv2D(256, 4, strides=2, padding='same')(x)  \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "  \n",
    "    x = layers.Conv2D(512, 4, strides=2, padding='same')(x)  \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "\n",
    "    x = layers.Conv2D(512, 4, strides=2, padding='same')(x)  \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    text_proj = layers.Dense(x.shape[-1], activation='relu')(text_input)\n",
    "    ca_text = ConditioningAugmentation(x.shape[-1])(text_proj)\n",
    "\n",
    "    x = layers.Concatenate()([x, ca_text])\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "\n",
    "    return tf.keras.Model([image_input, text_input], x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 16:07:48.699209: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for _ in range(n_critic):  \n",
    "    discriminator = make_discriminator()\n",
    "\n",
    "generator = make_generator()\n",
    "\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return -tf.reduce_mean(fake_output)  \n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    return tf.reduce_mean(tf.nn.relu(1.0 - real_output)) + tf.reduce_mean(tf.nn.relu(1.0 + fake_output))\n",
    "\n",
    "def gradient_penalty(discriminator, real_images, fake_images, text_embeddings):\n",
    "    alpha = tf.random.uniform([real_images.shape[0], 1, 1, 1], 0.0, 1.0)\n",
    "    interpolated_images = alpha * real_images + (1 - alpha) * fake_images\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated_images)\n",
    "        interpolated_output = discriminator([interpolated_images, text_embeddings], training=True)\n",
    "    grads = tape.gradient(interpolated_output, [interpolated_images])[0]\n",
    "    penalty = tf.reduce_mean((tf.norm(grads, ord=2) - 1.0) ** 2)\n",
    "    return penalty * 10  \n",
    "\n",
    "def add_noise(images, noise_factor=0.05):  \n",
    "    return images + noise_factor * tf.random.normal(shape=tf.shape(images))\n",
    "\n",
    "gen_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5, beta_2=0.999)\n",
    "disc_opt = tf.keras.optimizers.Adam(1e-4, beta_1=0.5, beta_2=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, captions):\n",
    "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        fake_images = generator([noise, captions], training=True)\n",
    "\n",
    "        real_output = discriminator([images, captions], training=True)\n",
    "        fake_output = discriminator([fake_images, captions], training=True)\n",
    "\n",
    "        gp = gradient_penalty(discriminator, images, fake_images, captions)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output) + gp\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    gen_opt.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    disc_opt.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_image(epoch):\n",
    "    test_caption = \"a foggy sky\" \n",
    "    seq = tokenizer.texts_to_sequences([test_caption])[0]\n",
    "    padded = pad_sequences([seq], maxlen=MAX_LEN)\n",
    "    padded_tensor = tf.constant(padded, dtype=tf.int32)\n",
    "\n",
    "    noise = tf.random.normal([1, NOISE_DIM])\n",
    "\n",
    "    embedding = embedding_layer(padded_tensor)          \n",
    "    embedding_mean = tf.reduce_mean(embedding, axis=1)\n",
    "\n",
    "    generated = generator([noise, embedding_mean], training=False)\n",
    "    img = (generated[0] + 1.0) / 2.0\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.savefig(f\"gen_images/generated_image_epoch_{epoch + 1}.png\")\n",
    "    plt.title(f\"Epoch {epoch + 1}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from checkpoint: ./checkpoints/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = './checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(generator=generator,\n",
    "                                 discriminator=discriminator,\n",
    "                                 g_optimizer=gen_opt,\n",
    "                                 d_optimizer=disc_opt)\n",
    "\n",
    "latest_ckpt = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "if latest_ckpt:\n",
    "    checkpoint.restore(latest_ckpt)\n",
    "    print(f\"Restored from checkpoint: {latest_ckpt}\")\n",
    "else:\n",
    "    print(\"Starting training from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for image_batch, caption_batch in dataset:\n",
    "            g_loss, d_loss = train_step(image_batch, caption_batch)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Gen Loss: {g_loss:.4f}, Disc Loss: {d_loss:.4f}\")\n",
    "    \n",
    "        if (epoch + 1) % 10 == 0 or epoch == epochs - 1:\n",
    "            save_generated_image(epoch)\n",
    "            \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "        \n",
    "tf.config.optimizer.set_jit(True)\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1744367883.698038   52810 meta_optimizer.cc:967] remapper failed: INVALID_ARGUMENT: Mutation::Apply error: fanout 'gradient_tape/functional_1_3/leaky_re_lu_5_1/LeakyRelu/LeakyReluGrad_1' exist for missing node 'functional_1_3/conv2d_5_1/BiasAdd'.\n"
     ]
    }
   ],
   "source": [
    "train(load_image_caption_dataset('./data/images', './data/captions.txt'), EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('generator_model.keras')\n",
    "discriminator.save('discriminator_model.keras') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
